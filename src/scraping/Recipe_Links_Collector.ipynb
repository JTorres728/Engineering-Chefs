{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kr5oEBdDqnG"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Request the Recipes A-Z page and store the link of each category page in an array\n",
        "url = 'https://www.allrecipes.com/recipes-a-z-6735880'\n",
        "soup = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "categories = []\n",
        "for link in soup.find_all('a', {'class': 'link-list__link type--dog-bold type--dog-link'}):\n",
        "  categories.append(link.get('href'))\n",
        "print(categories[0:5])  # Print the first 5 links to test whether it worked"
      ],
      "metadata": {
        "id": "RoE5EqfSEMKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now visit every category link and append 21 links from each\n",
        "# Only limited to 21 since scraping all links from each category page\n",
        "# could result in over 22000 recipe links!\n",
        "links = []\n",
        "count = 0\n",
        "\n",
        "for i in categories:\n",
        "  soup = BeautifulSoup(requests.get(i).content, 'html.parser')\n",
        "  for a in soup.find_all(\"a\", {'class': 'mntl-card-list-items'}):\n",
        "    links.append(a.get(\"href\"))\n",
        "    count += 1\n",
        "    if count > 20:\n",
        "      break\n",
        "  count = 0\n",
        "  sleep_time = np.random.uniform(1,5)\n",
        "  time.sleep(sleep_time)  # IMPORTANT: Need to wait before sending new request\n",
        "                          # in order to avoid overloading their server\n",
        "\n",
        "print(len(links)) # Prints how many recipe links collected"
      ],
      "metadata": {
        "id": "m_7G_A3YFpc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Links put in a Pandas series so that it can be filtered for noise later\n",
        "# For now, raw output saved as CSV to avoid losing data in case runtime disconnects\n",
        "links_out = pd.Series(links)\n",
        "df_links = links_out.to_frame(name='URL')\n",
        "print(df_links)\n",
        "df_links.to_csv(\"Recipe_Links_Raw.csv\")"
      ],
      "metadata": {
        "id": "PrcczQBoOLWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some links scraped are not recipe links (articles, blogs, etc)\n",
        "# Only links with '/recipe/' in the URL are recipes\n",
        "# Must filter everything else out, including duplicates\n",
        "links_out_filtered = links_out[(links_out.str.contains(\"/recipe/\")==True)].unique()\n",
        "print(links_out_filtered.size)"
      ],
      "metadata": {
        "id": "w1H2f2gyWiH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the filtered series in a Dataframe\n",
        "links_out_filtered = pd.Series(links_out_filtered)\n",
        "df_links_filtered = links_out_filtered.to_frame(name='URL')\n",
        "print(df_links_filtered)"
      ],
      "metadata": {
        "id": "3O1OsdNxW9OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lastly, output filtered results as CSV\n",
        "df_links_filtered.to_csv('Recipe_Links_Filtered.csv')"
      ],
      "metadata": {
        "id": "UOOqKQD2Xse3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}