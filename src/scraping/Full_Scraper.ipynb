{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH7Sv62Xrn4v"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries, including the RecipeScraper itself\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from RecipeScraper import RecipeScraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV containing URLs as a Pandas Dataframe\n",
        "# Helps make reading the URLs easier\n",
        "df = pd.read_csv('Recipe_Links_Filtered.csv')"
      ],
      "metadata": {
        "id": "2ifnv6IlsZYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The actual attributes present in the CSV database are specified in an array\n",
        "cols = ['URL',\n",
        "        'Title',\n",
        "        'Author',\n",
        "        'Date',\n",
        "        'Rating',\n",
        "        'Prep Time',\n",
        "        'Cook Time',\n",
        "        'Total Time',\n",
        "        'Servings',\n",
        "        'Calories',\n",
        "        'Carbs',\n",
        "        'Fat',\n",
        "        'Protien',\n",
        "        'Description',\n",
        "        'Ingredients',\n",
        "        'Instructions']\n",
        "\n",
        "df_full = pd.DataFrame(columns=cols) # These attributes are then used to make\n",
        "                                     # a dataframe for the database"
      ],
      "metadata": {
        "id": "MpKornBQu0IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before scraping multiple recipes, check to see if the scraper works properly on one recipe\n",
        "# Essentially a test\n",
        "scraper = RecipeScraper('https://www.allrecipes.com/recipe/275372/air-fryer-turkey-breast/')\n",
        "print(scraper.get_recipe_author())"
      ],
      "metadata": {
        "id": "aDajqaoQ0XGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So far, the dataframe for the database is empty\n",
        "# Use a loop to fill up the database one by one\n",
        "for i in range(300):\n",
        "  # Read one URL and pass it into the RecipeScraper constructor\n",
        "  url = df['URL'][i]\n",
        "  ex = RecipeScraper(url)\n",
        "\n",
        "  # Call every get function and store the info returned into the proper column in the row\n",
        "  df_full.at[i,'URL'] = url\n",
        "  df_full.at[i,'Title'] = ex.get_recipe_title()\n",
        "  df_full.at[i,'Author'] = ex.get_recipe_author()\n",
        "  df_full.at[i,'Date'] = ex.get_recipe_date()\n",
        "  df_full.at[i,'Rating'] = ex.get_recipe_rating()\n",
        "  df_full.at[i,'Description'] = ex.get_recipe_description()\n",
        "  df_full.at[i,'Ingredients'] = ex.get_recipe_ingredients()\n",
        "  df_full.at[i,'Instructions'] = ex.get_recipe_instructions()\n",
        "\n",
        "  # Details are returned as an array\n",
        "  details = ex.get_recipe_summary()\n",
        "\n",
        "  df_full.at[i,'Prep Time'] = details[0]  # Must read the returned array at\n",
        "  df_full.at[i,'Cook Time'] = details[1]  # speficic indexes to store into dataframe\n",
        "  df_full.at[i,'Total Time'] = details[2]\n",
        "  df_full.at[i,'Servings'] = details[3]\n",
        "\n",
        "  # Same case for nutrients\n",
        "  nutrients = ex.get_recipe_nutrition()\n",
        "\n",
        "  df_full.at[i,'Calories'] = nutrients[0]\n",
        "  df_full.at[i,'Carbs'] = nutrients[1]\n",
        "  df_full.at[i,'Fat'] = nutrients[2]\n",
        "  df_full.at[i,'Protien'] = nutrients[3]\n",
        "\n",
        "  sleep_time = np.random.uniform(1,5) # VERY IMPORTANT: Must wait before making\n",
        "  time.sleep(sleep_time)              # another request to avoid overwhelming their servers"
      ],
      "metadata": {
        "id": "I2Vb2cGuvYds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see whether data was written succesfully to rows\n",
        "print(df_full)"
      ],
      "metadata": {
        "id": "B5NWtMyrykjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, save everything as a CSV\n",
        "df_full.to_csv('recipes_full.csv')"
      ],
      "metadata": {
        "id": "MB1IyLeahI45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}